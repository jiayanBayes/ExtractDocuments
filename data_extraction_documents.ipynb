{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Information from Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Extract information from Microsoft Word Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EconS 524, Spring 2023\n",
      "Applied Machine Learning for Economics\n",
      "Time: Mon. and Wed. 4:10pm-5:25pm\n",
      "Location: Hulbert 23\n",
      "Credit 3, Course Prerequisites: EconS 525, 526 \n",
      "\n",
      "Jia Yan\n",
      "Office Hours (Hulbert 301E): Tuesday 2:00pm – 4:00pm\n",
      "E-mail: jiay@wsu.edu\n",
      "\n",
      "Class Website: canvas\n",
      "You will have to enter your WSU username and password to access the course materials.\n",
      "\n",
      "Class Description\n",
      "This course gives an overview of basic concepts and algorithms in machine learning and their connections to econometrics. The course will first review the following concepts and modeling techniques: linear and non-linear regressions, non-parametrics, support vector machine, random forests, supervised and non-supervised learning, deep learning, and natural language processing, and then discuss the applications of these techniques in economics.\n",
      "\n",
      "Readings:\n",
      "\n",
      "Required Text book: T. Hastie, R. Tibshirani and J. Friedman, , \n",
      " \n",
      "QuantEcon Data Science \n",
      "\n",
      "Course Objectives: This course is designed for Master and PhD students with interest in econometrics.  This course is intended to serve the following purposes:\n",
      "To learn the most recent machine learning and deep learning approaches from econometrics perspective\n",
      "To be able to apply machine learning and deep learning approaches on non-traditional data sources to analyze economics problems\n",
      "\n",
      "Grading Policy\n",
      "The grading policy is as follow: 30% Midterm, 30% Final Project, 30% Final, 10% class participation\n",
      "\n",
      "Course project: Students are required to finish a course project by April 30 2022. The project can be done by group and the maximal number of students in a group is 3. The requirements of the project are:\n",
      "Identify a valid empirical economics research question\n",
      "Compile a relevant data set for the research question\n",
      "Propose econometrics models that have components of machine learning or deep learning approaches\n",
      "Implement the models on the data using Python\n",
      "Write up the findings as a short research paper (no more than 20 pages)\n",
      " \n",
      "Schedule:\n",
      "\n",
      "• WSU Disability Statement: \n",
      "Students with Disabilities: Reasonable accommodations are available for students with a documented disability. If you have a disability and need accommodations to fully participate in this class, please either visit or call the Access Center (Washington Building 217; 509-335-3417) to schedule an appointment with an Access Advisor. All accommodations MUST be approved through the Access Center.\n",
      "\n",
      "• WSU Academic Honesty Statement:\n",
      "As an institution of higher education, Washington State University is committed to principles of truth and academic honesty. All members of the University community share the responsibility for maintaining and supporting these principles. When a student enrolls in Washington State University, the student assumes an obligation to pursue academic endeavors in a manner consistent with the standards of academic integrity adopted by the University. To maintain the academic integrity of the community, the University cannot tolerate acts of academic dishonesty including any forms of cheating, plagiarism, or fabrication. Washington State University reserves the right and the power to discipline or to exclude students who engage in academic dishonesty. Students found responsible for academic integrity violations may receive an F on the particular assignment or exam, as well as an F for the course.  Serious and/or repeated offenses may result in referral to the conduct board and expulsion from WSU. Cheating is defined in the Standards for Student Conduct WAC 504-26-010 (3). It is strongly suggested that you read and understand these definitions:  \n",
      "\n",
      "• WSU Safety Statement:\n",
      "Washington State University is committed to maintaining a safe environment for its faculty, staff, and students. Safety is the responsibility of every member of the campus community and individuals should know the appropriate actions to take when an emergency arises. In support of our commitment to the safety of the campus community the University has developed a Campus Safety Plan, . It is highly recommended that you visit this web site as well as the University emergency management web site at  to become familiar with the information provided.\n",
      "Table 1:\n",
      "['Week', 'Plan']\n",
      "['1', 'Introduction to statistical learning and Python programming']\n",
      "['2-7', 'Supervised Learning  \\nLinear Methods for Regression\\nLinear Methods for Classification\\nSupport Vector Machine\\nDecision Tree and Random Forests']\n",
      "['8', 'Un-supervised learning \\nClustering\\nDimension reduction: PCA, Factor Analysis']\n",
      "['9-10', 'Deep learning: introduction to neural networks']\n",
      "['11', 'Natural language processing (NLP) techniques']\n",
      "['12-13', 'Introduction to the following techniques: resampling, bootstrap, boosting, ensembling']\n",
      "['14', 'Applications in economics: prediction, classification, sentiment analysis']\n",
      "Text: , URL: http://web.stanford.edu/~hastie/ElemStatLearn/\n",
      "Text: , URL: http://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12_toc.pdf\n",
      "Text: , URL: https://datascience.quantecon.org/\n",
      "Text: , URL: http://conduct.wsu.edu/default.asp?PageID=338\n",
      "Text: , URL: http://safetyplan.wsu.edu\n",
      "Text: , URL: http://oem.wsu.edu/emergencies\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "\n",
    "def extract_text_from_docx(docx_path):\n",
    "    # Load the Word document\n",
    "    doc = Document(docx_path)\n",
    "    \n",
    "    # List to hold all the text in the document\n",
    "    full_text = []\n",
    "\n",
    "    # Iterate over each paragraph in the document\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "\n",
    "    # Join all the text separated by a newline\n",
    "    return '\\n'.join(full_text)\n",
    "\n",
    "def extract_tables_from_docx(docx_path):\n",
    "    # Load the Word document\n",
    "    doc = Document(docx_path)\n",
    "    \n",
    "    # List to hold all tables data\n",
    "    tables_data = []\n",
    "\n",
    "    # Iterate over each table in the document\n",
    "    for table in doc.tables:\n",
    "        table_text = []\n",
    "        for row in table.rows:\n",
    "            row_data = []\n",
    "            for cell in row.cells:\n",
    "                row_data.append(cell.text.strip())\n",
    "            table_text.append(row_data)\n",
    "        tables_data.append(table_text)\n",
    "    \n",
    "    return tables_data\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "def extract_hyperlinks(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    hyperlinks = []\n",
    "\n",
    "    # Define the WordprocessingML namespace\n",
    "    w_namespace = '{http://schemas.openxmlformats.org/wordprocessingml/2006/main}'\n",
    "    r_namespace = '{http://schemas.openxmlformats.org/officeDocument/2006/relationships}'\n",
    "\n",
    "    # Helper function to process hyperlink elements\n",
    "    def process_hyperlink(hyperlink_el, rels):\n",
    "        r_id = hyperlink_el.get(r_namespace + 'id')\n",
    "        if r_id and r_id in rels:\n",
    "            link = rels[r_id]._target\n",
    "            text = ''.join(node.text for node in hyperlink_el if node.tag == w_namespace + 't')\n",
    "            hyperlinks.append({'text': text, 'url': link})\n",
    "\n",
    "    # Get the relationships dictionary\n",
    "    rels = doc.part.rels\n",
    "\n",
    "    # Iterate through the document elements to find hyperlinks\n",
    "    for el in doc.element.body.iter():\n",
    "        if el.tag == w_namespace + 'hyperlink':\n",
    "            process_hyperlink(el, rels)\n",
    "\n",
    "    return hyperlinks\n",
    "\n",
    "\n",
    "inP = \"C:\\\\EconS524\\\\EconS524 Syllabus.docx\"\n",
    "text = extract_text_from_docx(inP)\n",
    "print(text)\n",
    "\n",
    "tables = extract_tables_from_docx(inP)\n",
    "\n",
    "# Print all extracted table data\n",
    "for i, table in enumerate(tables, start=1):\n",
    "    print(f\"Table {i}:\")\n",
    "    for row in table:\n",
    "        print(row)\n",
    "\n",
    "hyperlinks = extract_hyperlinks(inP)\n",
    "\n",
    "for hyperlink in hyperlinks:\n",
    "    print(f\"Text: {hyperlink['text']}, URL: {hyperlink['url']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: Extract from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiay\\Anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EconS 524, Spring 2023 \n",
      "\n",
      "Applied Machine Learning for Economics \n",
      "Time: Mon. and Wed. 4:10pm-5:25pm \n",
      "\n",
      "Location: Hulbert 23 \n",
      "\n",
      "Credit 3, Course Prerequisites: EconS 525, 526  \n",
      "\n",
      "4.  Implement the models on the data using Python \n",
      "5.  Write up the findings as a short research paper (no more than 20 pages) \n",
      "\n",
      "approaches \n",
      "\n",
      "  \n",
      "\n",
      " \n",
      "Jia Yan \n",
      "Office Hours (Hulbert 301E): Tuesday 2:00pm – 4:00pm \n",
      "E-mail: jiay@wsu.edu \n",
      " \n",
      "Class Website: canvas \n",
      "You will have to enter your WSU username and password to access the course materials. \n",
      " \n",
      "Class Description \n",
      "This course gives an overview of basic concepts and algorithms in machine learning and \n",
      "their connections to econometrics. The course will first review the following concepts and \n",
      "modeling techniques: linear and non-linear regressions, non-parametrics, support vector \n",
      "machine,  random  forests,  supervised  and  non-supervised  learning,  deep  learning,  and \n",
      "natural  language  processing,  and  then  discuss  the  applications  of  these  techniques  in \n",
      "economics. \n",
      " \n",
      "Readings: \n",
      " \n",
      "\n",
      "1.  Required Text book: T. Hastie, R. Tibshirani and J. Friedman, The Elements of \n",
      "\n",
      "Statistical Learning: Data Mining, Inference, and Prediction (2nd edition), \n",
      "http://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12_toc.pdf \n",
      "  \n",
      "\n",
      "2.  QuantEcon Data Science https://datascience.quantecon.org/ \n",
      "\n",
      " \n",
      "Course Objectives: This course is designed for Master and PhD students with interest in \n",
      "econometrics.  This course is intended to serve the following purposes: \n",
      "\n",
      "1.  To learn the most recent machine learning and deep learning approaches from \n",
      "\n",
      "econometrics perspective \n",
      "\n",
      "2.  To be able to apply machine learning and deep learning approaches on non-\n",
      "\n",
      "traditional data sources to analyze economics problems \n",
      "\n",
      " \n",
      "Grading Policy \n",
      "The grading policy is as follow: 30% Midterm, 30% Final Project, 30% Final, 10% class \n",
      "participation \n",
      " \n",
      "Course project: Students are required to finish a course project by April 30 2022. The project \n",
      "can be done by group and the maximal number of students in a group is 3. The requirements of \n",
      "the project are: \n",
      "\n",
      "1.  Identify a valid empirical economics research question \n",
      "2.  Compile a relevant data set for the research question \n",
      "3.  Propose econometrics models that have components of machine learning or deep learning \n",
      "\n",
      "\f",
      "Plan \n",
      "Introduction to statistical learning and Python programming \n",
      "Supervised Learning   \n",
      "\n",
      "1.  Linear Methods for Regression \n",
      "2.  Linear Methods for Classification \n",
      "3.  Support Vector Machine \n",
      "4.  Decision Tree and Random Forests \n",
      "\n",
      "Un-supervised learning  \n",
      "\n",
      "1.  Clustering \n",
      "2.  Dimension reduction: PCA, Factor Analysis \n",
      "\n",
      "Deep learning: introduction to neural networks \n",
      "Natural language processing (NLP) techniques \n",
      "Introduction to the following techniques: resampling, bootstrap, \n",
      "boosting, ensembling \n",
      "Applications in economics: prediction, classification, sentiment \n",
      "analysis \n",
      "\n",
      "Schedule: \n",
      "\n",
      "Week \n",
      "1 \n",
      "2-7 \n",
      "\n",
      "8 \n",
      "\n",
      "9-10 \n",
      "11 \n",
      "12-13 \n",
      "\n",
      "14 \n",
      "\n",
      " \n",
      "• WSU Disability Statement:  \n",
      "Students with Disabilities: Reasonable accommodations are available for students with a \n",
      "documented disability. If you have a disability and need accommodations to fully participate in \n",
      "this class, please either visit or call the Access Center (Washington Building 217; 509-335-3417) \n",
      "to schedule an appointment with an Access Advisor. All accommodations MUST be approved \n",
      "through the Access Center. \n",
      " \n",
      "• WSU Academic Honesty Statement: \n",
      "As an institution of higher education, Washington State University is committed to principles of \n",
      "truth and academic honesty. All members of the University community share the responsibility \n",
      "for maintaining and supporting these principles. When a student enrolls in Washington State \n",
      "University, the student assumes an obligation to pursue academic endeavors in a manner \n",
      "consistent with the standards of academic integrity adopted by the University. To maintain the \n",
      "academic integrity of the community, the University cannot tolerate acts of academic dishonesty \n",
      "including any forms of cheating, plagiarism, or fabrication. Washington State University reserves \n",
      "the right and the power to discipline or to exclude students who engage in academic dishonesty. \n",
      "Students found responsible for academic integrity violations may receive an F on the particular \n",
      "assignment or exam, as well as an F for the course.  Serious and/or repeated offenses may result \n",
      "in referral to the conduct board and expulsion from WSU. Cheating is defined in the Standards \n",
      "for Student Conduct WAC 504-26-010 (3). It is strongly suggested that you read and understand \n",
      "these definitions: http://conduct.wsu.edu/default.asp?PageID=338  \n",
      " \n",
      "• WSU Safety Statement: \n",
      "Washington State University is committed to maintaining a safe environment for its faculty, staff, \n",
      "and students. Safety is the responsibility of every member of the campus community and \n",
      "individuals should know the appropriate actions to take when an emergency arises. In support of \n",
      "our commitment to the safety of the campus community the University has developed a Campus \n",
      "Safety Plan, http://safetyplan.wsu.edu. It is highly recommended that you visit this web site as \n",
      "\n",
      "\f",
      "well as the University emergency management web site at http://oem.wsu.edu/emergencies to \n",
      "become familiar with the information provided. \n",
      "\n",
      "\f",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got stderr: Jan 16, 2024 8:38:50 PM org.apache.pdfbox.pdmodel.font.FileSystemFontProvider loadDiskCache\r\n",
      "WARNING: New fonts found, font cache will be re-built\r\n",
      "Jan 16, 2024 8:38:50 PM org.apache.pdfbox.pdmodel.font.FileSystemFontProvider <init>\r\n",
      "WARNING: Building on-disk font cache, this may take a while\r\n",
      "Jan 16, 2024 8:38:51 PM org.apache.pdfbox.pdmodel.font.FileSystemFontProvider <init>\r\n",
      "WARNING: Finished building on-disk font cache, found 380 fonts\r\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 0:\n",
      "    Week                                               Plan\n",
      "0      1  Introduction to statistical learning and Pytho...\n",
      "1    2-7  Supervised Learning\\r1.\\rLinear Methods for Re...\n",
      "2      8  Un-supervised learning\\r1.\\rClustering\\r2.Dime...\n",
      "3   9-10     Deep learning: introduction to neural networks\n",
      "4     11       Natural language processing (NLP) techniques\n",
      "5  12-13  Introduction to the following techniques: resa...\n",
      "6     14  Applications in economics: prediction, classif...\n"
     ]
    }
   ],
   "source": [
    "import tabula\n",
    "from io import StringIO\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "\n",
    "def extract_text_from_pdf(path):\n",
    "    '''\n",
    "    This script defines a function extract_text_from_pdf which:\n",
    "\n",
    "    1. Opens a PDF file in binary read mode.\n",
    "    2. Creates a PDF parser for the file and a PDF document object from the parser.\n",
    "    3. Initializes a resource manager and a text converter with layout parameters.\n",
    "    4. Sets up a PDF page interpreter.\n",
    "    5. Iterates over each page in the PDF document and processes it to extract the text.\n",
    "    6. Captures the extracted text into a StringIO object.\n",
    "    7. Retrieves the value from the StringIO object, closes it, and then returns the text.\n",
    "    '''\n",
    "    output_string = StringIO()\n",
    "    with open(path, 'rb') as in_file:\n",
    "        parser = PDFParser(in_file)\n",
    "        doc = PDFDocument(parser)\n",
    "        rsrcmgr = PDFResourceManager()\n",
    "        device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
    "        interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "        for page in PDFPage.create_pages(doc):\n",
    "            interpreter.process_page(page)\n",
    "\n",
    "    text = output_string.getvalue()\n",
    "    output_string.close()\n",
    "    return text\n",
    "   \n",
    "def extract_tables_from_pdf(path):\n",
    "    '''\n",
    "    You need to have Java installed on your system to use Tabula. \n",
    "    '''\n",
    "    df = tabula.read_pdf(path, pages='all', multiple_tables=True)\n",
    "    return df \n",
    "\n",
    "inP = \"C:\\\\EconS524\\\\EconS524 Syllabus.pdf\"\n",
    "pdf_text = extract_text_from_pdf(inP)\n",
    "print(pdf_text)\n",
    "\n",
    "tables =  extract_tables_from_pdf(inP)\n",
    "for i, table in enumerate(tables):\n",
    "    print(f\"Table {i}:\")\n",
    "    print(table)\n",
    "    # You can also export to CSV, Excel, etc.\n",
    "    # table.to_csv(f\"table_{i}.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Extract from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHitg fim Alive Tle mage\n",
      "Tiny CHANGES To CARTH\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import platform\n",
    "from PIL import Image, ImageFilter, ImageEnhance\n",
    "\n",
    "def image_to_text(image_file_path, openCV=True):\n",
    "    if platform.system() == \"Windows\":\n",
    "        # this sentence should be platform independent; under winsdows need the following command\n",
    "        pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "    \n",
    "    if openCV:\n",
    "        # load image\n",
    "        image = cv2.imread(image_file_path)\n",
    "\n",
    "        # Convert the image to grayscale\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply adaptive thresholding to create a binary image\n",
    "        _,thresh1 = cv2.threshold(image,120,255,cv2.THRESH_BINARY)\n",
    "\n",
    "        # Perform OCR using Tesseract\n",
    "        text = pytesseract.image_to_string(thresh1, lang='eng')\n",
    "    else:\n",
    "        # Load the image from the specified path\n",
    "        img = Image.open(image_file_path)\n",
    "    \n",
    "        # Convert the image to grayscale to improve OCR accuracy\n",
    "        img = img.convert('L')\n",
    "\n",
    "        # Enhance the image contrast\n",
    "        enhancer = ImageEnhance.Contrast(img)\n",
    "        img = enhancer.enhance(2)\n",
    "    \n",
    "        # Apply a threshold filter to make the image binary\n",
    "        img = img.point(lambda x: 0 if x < 128 else 255, '1')\n",
    "    \n",
    "        # Optional: resize the image to double its size, to make it easier for Tesseract to read\n",
    "        img = img.resize([2 * s for s in img.size], Image.LANCZOS)   \n",
    "        \n",
    "        # Perform OCR on the grayscale image\n",
    "        text = pytesseract.image_to_string(img, lang='eng')\n",
    "    return text\n",
    "\n",
    "inP = \"C:\\\\EconS524\\\\hand_writing.jpg\"\n",
    "text = image_to_text(inP, openCV='False')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4: Extract PDF Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PdfOcrExtract(object): \n",
    "    \n",
    "    def __init__(self, inpath, recycle=None, poppler_path=None, image_type=\"png\", image_dpi=300, size=None,\n",
    "                 paddle=True):\n",
    "        self.inpath = inpath\n",
    "        self.dpi = image_dpi\n",
    "        self.image_type = image_type\n",
    "        self.poppler_path = poppler_path   \n",
    "        self.size = size         \n",
    "        self.paddle = paddle\n",
    "        if recycle is None:\n",
    "            # recycle is a temporary directory to store temporary image files\n",
    "            tmp = os.path.join(inpath, \"recycle\")\n",
    "            if os.path.isdir(tmp):\n",
    "                shutil.rmtree(tmp)\n",
    "            self.recycle = tmp\n",
    "            os.mkdir(tmp)\n",
    "        else:\n",
    "            self.recycle = recycle\n",
    "\n",
    "    def empty_folder_images(self):\n",
    "        '''\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "        Empty all image files from the recycle directory\n",
    "        '''\n",
    "        try:\n",
    "            filelist = [ f for f in os.listdir(self.recycle) if f.endswith(self.image_type) ]\n",
    "            for f in filelist:\n",
    "                os.remove(os.path.join(self.recycle, f))\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    def images_by_page(self, path):\n",
    "        convert_from_path(path, fmt=self.image_type, \n",
    "                                  dpi=self.dpi, output_folder=self.recycle, use_cropbox=False,\n",
    "                                  poppler_path=self.poppler_path, size=self.size)\n",
    "    \n",
    "    def image_to_text(self, image_file):\n",
    "        import platform\n",
    "        if platform.system() == \"Windows\":\n",
    "            # this sentence should be platform independent; under winsdows need the following command\n",
    "            pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "    \n",
    "        # load image\n",
    "        image = cv2.imread(os.path.join(self.recycle, image_file))\n",
    "    \n",
    "        # convert the image to black and white for better OCR\n",
    "        ret,thresh1 = cv2.threshold(image,120,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "        # pytesseract image to string to get results\n",
    "        text = pytesseract.image_to_string(thresh1, lang='eng') \n",
    "        text = text.strip().replace(\"\\n\", \"\")\n",
    "        return text\n",
    "    \n",
    "    def batch_text_extract(self):\n",
    "        filelist = [ f for f in os.listdir(self.recycle) if f.endswith(self.image_type) ]\n",
    "        filelist.sort()\n",
    "        x = list(map(self.image_to_text, filelist))\n",
    "        return \"\".join(item for item in x)\n",
    "\n",
    "    def text_extraction_file(self, file):\n",
    "        # initialize the folder of storing intermediate image files \n",
    "        self.empty_folder_images()\n",
    "        try:\n",
    "            # convert each page of a file to an image file\n",
    "            self.images_by_page(file)\n",
    "            # extract text from all the images\n",
    "            contents = self.batch_text_extract().replace(\" \", \"\")\n",
    "        except Exception as e:\n",
    "            print('Exception',e)\n",
    "            contents = \"\"\n",
    "        return contents\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
